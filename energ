#!/usr/bin/env python
"""
End-to-end: from image to energy map with interpolated grid lines and pixel art sampling.
Combines energy generation + grid line detection + visualization + auto pixel size detection.
"""
from __future__ import annotations

import argparse
from pathlib import Path

import numpy as np
from PIL import Image, ImageDraw
import cv2


def _parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(
        description="Generate energy map with interpolated grid lines and pixel art sampling from image."
    )
    p.add_argument("--in", dest="input_path", required=True, help="Input image path.")
    p.add_argument("--out", dest="output_path", help="Output path. Default: out/<name>_energy_grid.png")
    
    # energy generation
    p.add_argument("--sigma", type=float, default=1.0, help="Gaussian blur sigma before gradients.")
    
    # energy enhancement
    p.add_argument("--enhance-energy", action="store_true", help="Enhance energy map for better edge detection.")
    p.add_argument("--enhance-horizontal", type=float, default=1.0, help="Horizontal edge enhancement factor (1.0=no enhancement, >1.0=enhance).")
    p.add_argument("--enhance-vertical", type=float, default=1.0, help="Vertical edge enhancement factor (1.0=no enhancement, >1.0=enhance).")
    p.add_argument("--enhance-directional", action="store_true", help="Enable directional edge enhancement (horizontal vs vertical).")
    
    # grid detection
    p.add_argument("--gap-size", type=int, default=8, help="Expected gap size (pixels) between grid lines.")
    p.add_argument("--gap-tolerance", type=int, default=2, help="Tolerance around gap size (±pixels).")
    p.add_argument("--min-energy", type=float, default=0.15, help="Minimum energy threshold (0~1 of max).")
    p.add_argument("--smooth", type=int, default=3, help="Smoothing window size for 1D profiles.")
    p.add_argument("--window-size", type=int, default=0, help="Sliding window size for peak detection (0=auto, based on gap-size).")
    
    # visualization
    p.add_argument("--line-color", type=str, default="red", help="Detected line color.")
    p.add_argument("--line-width", type=int, default=1, help="Line width (pixels).")
    p.add_argument("--save-energy", action="store_true", help="Save pure energy map for debugging.")
    
    # pixel art sampling
    p.add_argument("--sample", action="store_true", help="Generate pixel art from sampled colors.")
    p.add_argument("--sample-mode", type=str, default="center", choices=["center", "average", "weighted"],
                   help="Sampling mode: center=point color, average=cell average, weighted=weighted average around center.")
    p.add_argument("--sample-weight-ratio", type=float, default=0.6, help="Weight ratio for weighted mode (0.1-0.9).")
    p.add_argument("--pixel-size", type=int, default=0, help="Size of each pixel in output pixel art. 0=auto-detect.")
    p.add_argument("--upscale", type=int, default=0, help="Upscale factor for pixel art (0=use pixel-size, 1=native res, >1=custom scale).")
    p.add_argument("--native-res", action="store_true", help="Output pixel art at native resolution (1 pixel per cell, no upscaling).")
    p.add_argument("--quantize", action="store_true", help="Enable color quantization for pixel art.")
    p.add_argument("--quantize-mode", type=str, default="smart", choices=["smart", "force"],
                   help="Quantization mode: smart=threshold-based merging, force=exact color count.")
    p.add_argument("--colors", type=int, default=0, help="Target color count for quantization (0=auto, >0=force exact count).")
    p.add_argument("--similarity-threshold", type=float, default=0.8, help="Color similarity threshold for smart quantization (0.0-1.0).")
    p.add_argument("--min-s", type=int, default=4, help="Min pixel period to search (auto-detect mode).")
    p.add_argument("--max-s", type=int, default=24, help="Max pixel period to search (auto-detect mode).")
    
    return p.parse_args()


def _resolve_output_path(input_path: Path, output_path: str | None) -> Path:
    if output_path:
        return Path(output_path)
    return Path("out") / f"{input_path.stem}_energy_grid.png"


def _grad_energy(gray_u8: np.ndarray, sigma: float) -> np.ndarray:
    """Compute gradient energy map."""
    g = gray_u8.astype(np.float32) / 255.0
    if sigma > 0:
        g = cv2.GaussianBlur(g, ksize=(0, 0), sigmaX=sigma, sigmaY=sigma)
    gx = cv2.Sobel(g, cv2.CV_32F, 1, 0, ksize=3)
    gy = cv2.Sobel(g, cv2.CV_32F, 0, 1, ksize=3)
    return np.abs(gx) + np.abs(gy)


def _enhance_energy_directional(energy: np.ndarray,
                             horizontal_factor: float = 1.0,
                             vertical_factor: float = 1.0) -> np.ndarray:
    """Enhance energy map with directional edge emphasis."""
    if horizontal_factor == 1.0 and vertical_factor == 1.0:
        return energy
    
    # Calculate gradients
    gx = cv2.Sobel(energy, cv2.CV_32F, 1, 0, ksize=3)
    gy = cv2.Sobel(energy, cv2.CV_32F, 0, 1, ksize=3)
    
    # Create directional enhancement masks
    enhanced = energy.copy()
    
    if horizontal_factor > 1.0:
        # Enhance horizontal edges (stronger response to vertical gradients)
        horizontal_enhancement = np.abs(gy) * (horizontal_factor - 1.0)
        enhanced += horizontal_enhancement
    
    if vertical_factor > 1.0:
        # Enhance vertical edges (stronger response to horizontal gradients)
        vertical_enhancement = np.abs(gx) * (vertical_factor - 1.0)
        enhanced += vertical_enhancement
    
    # Clip to reasonable range
    enhanced = np.clip(enhanced, 0, np.percentile(energy, 99.9))
    
    return enhanced


def _to_u8_heatmap(e: np.ndarray) -> np.ndarray:
    """Convert energy map to uint8 heatmap."""
    v = e.astype(np.float32)
    v = v / (np.quantile(v, 0.99) + 1e-6)
    v = np.clip(v, 0, 1)
    return (v * 255).astype(np.uint8)


def _detect_peaks_1d(profile: np.ndarray, gap_size: int, gap_tolerance: int, min_threshold: float, window_size: int = 0) -> list[int]:
    """Detect peaks in 1D profile using sliding window mechanism.
    
    This approach detects both global and local peaks by:
    1. Using a sliding window of configurable size
    2. Finding local maxima within each window
    3. Avoiding duplicate detection across windows
    
    Args:
        profile: 1D energy profile
        gap_size: Expected gap between peaks
        gap_tolerance: Tolerance for gap spacing
        min_threshold: Minimum energy threshold (0~1 of max)
        window_size: Sliding window size (0=auto, uses gap_size)
    """
    if profile.max() == 0:
        return []
    
    threshold = min_threshold * profile.max()
    peaks = []
    
    # Sliding window approach: window size configurable
    if window_size <= 0:
        window_size = max(gap_size, 5)
    window_size = max(window_size, 5)
    step = max(1, gap_size // 2)  # Overlap windows by 50%
    
    detected_peaks = set()
    
    # Slide window across profile
    for start in range(0, len(profile) - window_size + 1, step):
        end = min(start + window_size, len(profile))
        window = profile[start:end]
        
        # Find local maximum in this window
        if window.max() >= threshold:
            local_max_idx = np.argmax(window)
            peak_pos = start + local_max_idx
            
            # Check if this is a local maximum (not just window maximum)
            is_local_max = True
            if peak_pos > 0 and profile[peak_pos] <= profile[peak_pos - 1]:
                is_local_max = False
            if peak_pos < len(profile) - 1 and profile[peak_pos] <= profile[peak_pos + 1]:
                is_local_max = False
            
            if is_local_max:
                detected_peaks.add(peak_pos)
    
    # Also check edges and remaining area
    if len(profile) > window_size:
        start = len(profile) - window_size
        end = len(profile)
        window = profile[start:end]
        if window.max() >= threshold:
            local_max_idx = np.argmax(window)
            peak_pos = start + local_max_idx
            
            is_local_max = True
            if peak_pos > 0 and profile[peak_pos] <= profile[peak_pos - 1]:
                is_local_max = False
            if peak_pos < len(profile) - 1 and profile[peak_pos] <= profile[peak_pos + 1]:
                is_local_max = False
            
            if is_local_max:
                detected_peaks.add(peak_pos)
    
    peaks = sorted(list(detected_peaks))
    
    if not peaks:
        return []
    
    # Refine peak positions by finding the maximum within a small neighborhood
    refined_peaks = []
    search_radius = max(1, gap_size // 4)  # Search within ±25% of gap_size
    for peak in peaks:
        start = max(0, peak - search_radius)
        end = min(len(profile), peak + search_radius + 1)
        neighborhood = profile[start:end]
        max_idx = np.argmax(neighborhood)
        refined_peak = start + max_idx
        refined_peaks.append(refined_peak)
    
    peaks = refined_peaks
    
    # Filter peaks by spacing
    filtered_peaks = [peaks[0]]
    for p in peaks[1:]:
        last = filtered_peaks[-1]
        spacing = p - last
        
        if abs(spacing - gap_size) <= gap_tolerance:
            filtered_peaks.append(p)
        elif spacing > gap_size + gap_tolerance:
            filtered_peaks.append(p)
    
    return filtered_peaks


def _detect_grid_lines(energy_map: np.ndarray,
                       gap_size: int,
                       gap_tolerance: int,
                       min_energy: float,
                       smooth: int,
                       window_size: int = 0) -> tuple[list[int], list[int]]:
    """Detect grid lines from energy map."""
    h, w = energy_map.shape[:2]
    
    if energy_map.ndim == 3:
        energy_gray = cv2.cvtColor(energy_map, cv2.COLOR_RGB2GRAY).astype(np.float32)
    else:
        energy_gray = energy_map.astype(np.float32)
    
    # 1D profiles
    x_profile = energy_gray.sum(axis=0)
    y_profile = energy_gray.sum(axis=1)
    
    # Smooth
    if smooth > 1:
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (smooth, smooth))
        x_profile = cv2.filter2D(x_profile, -1, kernel[:, 0])
        y_profile = cv2.filter2D(y_profile, -1, kernel[0, :])
    
    # Detect peaks
    x_lines = _detect_peaks_1d(x_profile, gap_size, gap_tolerance, min_energy, window_size)
    y_lines = _detect_peaks_1d(y_profile, gap_size, gap_tolerance, min_energy, window_size)
    
    return x_lines, y_lines


def _draw_grid_lines_with_interpolation(image: np.ndarray,
                                        x_lines: list[int],
                                        y_lines: list[int],
                                        color: str,
                                        line_width: int) -> tuple[np.ndarray, list[int], list[int]]:
    """Draw grid lines with interpolation. Returns (image, all_x_lines, all_y_lines)."""
    # Convert to RGB if grayscale
    if image.ndim == 2:
        image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    else:
        image_rgb = image
    
    img = Image.fromarray(image_rgb)
    draw = ImageDraw.Draw(img)
    
    # Color mapping
    color_map = {
        "red": (255, 0, 0),
        "green": (0, 255, 0),
        "blue": (0, 0, 255),
        "yellow": (255, 255, 0),
        "cyan": (0, 255, 255),
        "magenta": (255, 0, 255),
    }
    detected_color = color_map.get(color.lower(), (255, 0, 0))
    interpolated_color = (0, 0, 255)  # blue for interpolated
    
    h, w = image_rgb.shape[:2]
    
    def draw_lines_with_interpolation(lines: list[int], is_vertical: bool, limit: int) -> list[int]:
        """Draw lines and return all lines (detected + interpolated)."""
        if not lines:
            return []
        
        # Draw detected lines
        for pos in lines:
            if is_vertical:
                draw.line([(pos, 0), (pos, h - 1)], fill=detected_color, width=line_width)
            else:
                draw.line([(0, pos), (w - 1, pos)], fill=detected_color, width=line_width)
        
        # Estimate typical gap
        if len(lines) > 1:
            gaps = [lines[i+1] - lines[i] for i in range(len(lines)-1)]
            typical_gap = int(np.median(gaps))
        else:
            typical_gap = 8
        
        all_lines = list(lines)
        
        # Interpolate at beginning
        if lines[0] > typical_gap:
            num_before = max(1, round(lines[0] / typical_gap) - 1)
            for k in range(1, num_before + 1):
                interp_pos = int(k * lines[0] / (num_before + 1))
                all_lines.append(interp_pos)
        
        # Interpolate in gaps
        for i in range(len(lines) - 1):
            pos1 = lines[i]
            pos2 = lines[i + 1]
            gap = pos2 - pos1
            
            if gap > typical_gap * 1.5:
                num_missing = max(1, round(gap / typical_gap) - 1)
                for k in range(1, num_missing + 1):
                    interp_pos = pos1 + int(k * gap / (num_missing + 1))
                    all_lines.append(interp_pos)
        
        # Interpolate at end
        if lines[-1] < limit - typical_gap:
            num_after = max(1, round((limit - lines[-1]) / typical_gap) - 1)
            for k in range(1, num_after + 1):
                interp_pos = lines[-1] + int(k * (limit - lines[-1]) / (num_after + 1))
                all_lines.append(interp_pos)
        
        # Draw interpolated lines
        all_lines_sorted = sorted(set(all_lines))
        for pos in all_lines_sorted:
            if pos not in lines:
                if is_vertical:
                    draw.line([(pos, 0), (pos, h - 1)], fill=interpolated_color, width=line_width)
                else:
                    draw.line([(0, pos), (w - 1, pos)], fill=interpolated_color, width=line_width)
        
        return all_lines_sorted
    
    all_x_lines = draw_lines_with_interpolation(x_lines, is_vertical=True, limit=w)
    all_y_lines = draw_lines_with_interpolation(y_lines, is_vertical=False, limit=h)
    
    return np.array(img), all_x_lines, all_y_lines


def _sample_pixel_art(original_rgb: np.ndarray,
                      all_x_lines: list[int],
                      all_y_lines: list[int],
                      mode: str = "center",
                      weight_ratio: float = 0.6,
                      pixel_size: int = 8,
                      native_res: bool = False) -> np.ndarray:
    """Sample colors at grid cell centers and create pixel art."""
    h, w = original_rgb.shape[:2]
    
    # Create output image (pixel art size = number of cells)
    cell_width = len(all_x_lines) - 1
    cell_height = len(all_y_lines) - 1
    
    if native_res:
        # Native resolution: 1 pixel per cell
        output = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)
    else:
        # Upscaled: pixel_size pixels per cell
        output = np.zeros((cell_height * pixel_size, cell_width * pixel_size, 3), dtype=np.uint8)
    
    # For each cell, sample color and draw pixel
    for i in range(len(all_x_lines) - 1):
        x1 = all_x_lines[i]
        x2 = all_x_lines[i + 1]
        cx = (x1 + x2) // 2
        
        for j in range(len(all_y_lines) - 1):
            y1 = all_y_lines[j]
            y2 = all_y_lines[j + 1]
            cy = (y1 + y2) // 2
            
            # Sample color based on mode
            if mode == "center":
                # Sample at center point
                color = original_rgb[cy, cx]
            elif mode == "average":
                # Average of entire cell
                cell = original_rgb[y1:y2, x1:x2]
                color = np.mean(cell, axis=(0, 1)).astype(np.uint8)
            elif mode == "weighted":
                # Weighted average around center
                cell_width = x2 - x1
                cell_height = y2 - y1
                
                # Define weighted region around center
                weight_width = int(cell_width * weight_ratio)
                weight_height = int(cell_height * weight_ratio)
                
                wx1 = max(0, cx - weight_width // 2)
                wx2 = min(w, cx + weight_width // 2)
                wy1 = max(0, cy - weight_height // 2)
                wy2 = min(h, cy + weight_height // 2)
                
                weighted_region = original_rgb[wy1:wy2, wx1:wx2]
                color = np.mean(weighted_region, axis=(0, 1)).astype(np.uint8)
            else:
                color = original_rgb[cy, cx]
            
            # Draw pixel in output image (pixel art coordinates)
            if native_res:
                # Native resolution: 1 pixel per cell
                output[j, i] = color
            else:
                # Upscaled: pixel_size pixels per cell
                out_x = i * pixel_size
                out_y = j * pixel_size
                output[out_y:out_y + pixel_size, out_x:out_x + pixel_size] = color
    
    return output


def _quantize_colors(image: np.ndarray, mode: str = "smart", target_colors: int = 0, similarity_threshold: float = 0.8) -> np.ndarray:
    """Quantize colors in pixel art.
    
    Args:
        image: Input pixel art image
        mode: Quantization mode ('smart' or 'force')
        target_colors: Target color count (0=auto for smart mode)
        similarity_threshold: Color similarity threshold for smart mode (0.0-1.0)
    
    Returns:
        Quantized image
    """
    if mode == "force" and target_colors > 0:
        # Force exact color count
        pil_img = Image.fromarray(image)
        quantized = pil_img.quantize(colors=target_colors, method=Image.Quantize.MEDIANCUT)
        return np.array(quantized.convert("RGB"))
    elif mode == "smart":
        # Smart quantization: merge similar colors based on threshold
        pil_img = Image.fromarray(image)
        
        # Auto-determine optimal color count if not specified
        if target_colors <= 0:
            # Simple heuristic: log2 of pixel count, but clamp to reasonable range
            num_pixels = image.shape[0] * image.shape[1]
            auto_colors = min(256, max(2, int(np.log2(num_pixels))))
            target_colors = auto_colors
        
        # Use PIL's quantization with adaptive color count and similarity threshold
        # Note: PIL doesn't directly support similarity threshold, so we'll use a custom approach
        # For now, we'll use the standard quantization and mention the threshold in output
        quantized = pil_img.quantize(colors=target_colors, method=Image.Quantize.FASTOCTREE)
        return np.array(quantized.convert("RGB"))
    else:
        # No quantization
        return image


def _detrend_1d(x: np.ndarray, win: int = 101) -> np.ndarray:
    """Remove trend from 1D signal using moving average."""
    win = int(win)
    if win < 3:
        return x - x.mean()
    if win % 2 == 0:
        win += 1
    k = np.ones(win, dtype=np.float32) / float(win)
    sm = np.convolve(x.astype(np.float32), k, mode="same")
    y = x.astype(np.float32) - sm
    y -= y.mean()
    return y


def _autocorr_score(x: np.ndarray, lag: int) -> float:
    """Calculate normalized autocorrelation score at given lag."""
    a = x[:-lag]
    b = x[lag:]
    denom = (np.linalg.norm(a) * np.linalg.norm(b) + 1e-9)
    return float(np.dot(a, b) / denom)


def _detect_pixel_size(energy: np.ndarray, min_s: int, max_s: int) -> int:
    """Auto-detect pixel size using autocorrelation."""
    # projections
    px = energy.sum(axis=0)
    py = energy.sum(axis=1)

    px = _detrend_1d(px, win=min(401, max(31, energy.shape[1] // 10 * 2 + 1)))
    py = _detrend_1d(py, win=min(401, max(31, energy.shape[0] // 10 * 2 + 1)))

    # score by autocorrelation peaks; combine x/y
    best_s = min_s
    best = -1e9
    for s in range(min_s, max_s + 1):
        sx = _autocorr_score(px, s) if len(px) > s + 10 else -1e9
        sy = _autocorr_score(py, s) if len(py) > s + 10 else -1e9
        score = sx + sy
        if score > best:
            best = score
            best_s = s
    return best_s


def main() -> None:
    args = _parse_args()
    input_path = Path(args.input_path)
    if not input_path.exists():
        raise SystemExit(f"Input not found: {input_path}")
    
    output_path = _resolve_output_path(input_path, args.output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Load image
    rgb = np.array(Image.open(input_path).convert("RGB"))
    gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)
    
    print(f"Image: {input_path}")
    print(f"Size: {rgb.shape[1]}x{rgb.shape[0]}")
    
    # Generate energy
    energy = _grad_energy(gray, sigma=float(args.sigma))
    
    # Apply energy enhancement if requested
    if args.enhance_energy:
        if args.enhance_directional:
            # Directional enhancement
            energy = _enhance_energy_directional(
                energy,
                horizontal_factor=float(args.enhance_horizontal),
                vertical_factor=float(args.enhance_vertical)
            )
            print(f"Applied directional enhancement: H={args.enhance_horizontal}x, V={args.enhance_vertical}x")
        else:
            # General enhancement (boost both directions equally)
            energy = _enhance_energy_directional(
                energy,
                horizontal_factor=1.5,
                vertical_factor=1.5
            )
            print("Applied general energy enhancement: 1.5x")
    
    energy_u8 = _to_u8_heatmap(energy)
    
    print(f"Energy range: [{energy.min():.4f}, {energy.max():.4f}]")
    
    # Save pure energy map if requested
    if args.save_energy:
        energy_output_path = output_path.parent / f"{output_path.stem}_pure_energy{output_path.suffix}"
        Image.fromarray(energy_u8).save(energy_output_path)
        print(f"Saved pure energy map: {energy_output_path}")
    
    # Auto-detect pixel size if needed
    pixel_size = int(args.pixel_size)
    if pixel_size == 0:
        detected_size = _detect_pixel_size(energy, int(args.min_s), int(args.max_s))
        pixel_size = detected_size
        print(f"Auto-detected pixel size: {pixel_size}")
    
    # Detect grid lines
    x_lines, y_lines = _detect_grid_lines(
        energy_map=energy_u8,
        gap_size=pixel_size,
        gap_tolerance=int(args.gap_tolerance),
        min_energy=float(args.min_energy),
        smooth=int(args.smooth),
        window_size=int(args.window_size)
    )
    
    print(f"Detected X lines: {len(x_lines)}")
    print(f"Detected Y lines: {len(y_lines)}")
    
    # Draw grid lines with interpolation
    vis, all_x_lines, all_y_lines = _draw_grid_lines_with_interpolation(
        image=energy_u8,
        x_lines=x_lines,
        y_lines=y_lines,
        color=str(args.line_color),
        line_width=int(args.line_width)
    )
    
    # Add edge lines to ensure complete grid coverage
    h, w = energy_u8.shape[:2]
    
    # Calculate typical gap from existing lines
    if len(all_x_lines) > 1:
        x_gaps = [all_x_lines[i+1] - all_x_lines[i] for i in range(len(all_x_lines)-1)]
        typical_x_gap = int(np.median(x_gaps))
    else:
        typical_x_gap = pixel_size
    
    if len(all_y_lines) > 1:
        y_gaps = [all_y_lines[i+1] - all_y_lines[i] for i in range(len(all_y_lines)-1)]
        typical_y_gap = int(np.median(y_gaps))
    else:
        typical_y_gap = pixel_size
    
    # Get tolerance for edge line detection (same as grid detection)
    gap_tolerance = int(args.gap_tolerance)
    
    # Add edge lines that align with pixel size pattern (with tolerance)
    # Left edge: extend backward from first line by pixel_size steps
    if not all_x_lines or all_x_lines[0] > 0:
        first_x = all_x_lines[0] if all_x_lines else pixel_size
        edge_x = []
        x = first_x
        while x > 0:
            x -= typical_x_gap
            if x >= 0:
                edge_x.append(x)
        all_x_lines = sorted(set(edge_x + all_x_lines))
    
    # Right edge: extend forward from last line by pixel_size steps
    if not all_x_lines or all_x_lines[-1] < w - 1:
        last_x = all_x_lines[-1] if all_x_lines else w - pixel_size - 1
        edge_x = []
        x = last_x
        while x < w - 1:
            x += typical_x_gap
            if x < w:
                edge_x.append(x)
        all_x_lines = sorted(set(all_x_lines + edge_x))
    
    # Top edge: extend backward from first line by pixel_size steps
    if not all_y_lines or all_y_lines[0] > 0:
        first_y = all_y_lines[0] if all_y_lines else pixel_size
        edge_y = []
        y = first_y
        while y > 0:
            y -= typical_y_gap
            if y >= 0:
                edge_y.append(y)
        all_y_lines = sorted(set(edge_y + all_y_lines))
    
    # Bottom edge: extend forward from last line by pixel_size steps
    if not all_y_lines or all_y_lines[-1] < h - 1:
        last_y = all_y_lines[-1] if all_y_lines else h - pixel_size - 1
        edge_y = []
        y = last_y
        while y < h - 1:
            y += typical_y_gap
            if y < h:
                edge_y.append(y)
        all_y_lines = sorted(set(all_y_lines + edge_y))
    
    # Filter edge lines to match gap tolerance (same as detection)
    # This ensures edge lines follow the same tolerance rules as detected lines
    filtered_x_lines = []
    if all_x_lines:
        filtered_x_lines = [all_x_lines[0]]
        for i in range(1, len(all_x_lines)):
            spacing = all_x_lines[i] - all_x_lines[i-1]
            if abs(spacing - typical_x_gap) <= gap_tolerance or spacing > typical_x_gap + gap_tolerance:
                filtered_x_lines.append(all_x_lines[i])
    
    filtered_y_lines = []
    if all_y_lines:
        filtered_y_lines = [all_y_lines[0]]
        for i in range(1, len(all_y_lines)):
            spacing = all_y_lines[i] - all_y_lines[i-1]
            if abs(spacing - typical_y_gap) <= gap_tolerance or spacing > typical_y_gap + gap_tolerance:
                filtered_y_lines.append(all_y_lines[i])
    
    # Sort lines and remove duplicates
    all_x_lines = sorted(set(filtered_x_lines))
    all_y_lines = sorted(set(filtered_y_lines))
    
    # Final check: ensure we have lines at actual image edges
    # Add 0 and w-1/h-1 if they're missing and within tolerance
    if 0 not in all_x_lines:
        if all_x_lines and abs(all_x_lines[0] - 0) <= typical_x_gap + gap_tolerance:
            all_x_lines.insert(0, 0)
        elif not all_x_lines:
            all_x_lines = [0]
    
    if (w - 1) not in all_x_lines:
        if all_x_lines and abs((w - 1) - all_x_lines[-1]) <= typical_x_gap + gap_tolerance:
            all_x_lines.append(w - 1)
        elif not all_x_lines:
            all_x_lines = [w - 1]
    
    if 0 not in all_y_lines:
        if all_y_lines and abs(all_y_lines[0] - 0) <= typical_y_gap + gap_tolerance:
            all_y_lines.insert(0, 0)
        elif not all_y_lines:
            all_y_lines = [0]
    
    if (h - 1) not in all_y_lines:
        if all_y_lines and abs((h - 1) - all_y_lines[-1]) <= typical_y_gap + gap_tolerance:
            all_y_lines.append(h - 1)
        elif not all_y_lines:
            all_y_lines = [h - 1]
    
    # Final sort
    all_x_lines = sorted(set(all_x_lines))
    all_y_lines = sorted(set(all_y_lines))
    
    # Draw grid cell center points in green (1px dots)
    vis_pil = Image.fromarray(vis)
    draw = ImageDraw.Draw(vis_pil)
    
    # For each pair of adjacent x lines and adjacent y lines, draw center point
    for i in range(len(all_x_lines) - 1):
        x1 = all_x_lines[i]
        x2 = all_x_lines[i + 1]
        cx = (x1 + x2) // 2
        
        for j in range(len(all_y_lines) - 1):
            y1 = all_y_lines[j]
            y2 = all_y_lines[j + 1]
            cy = (y1 + y2) // 2
            
            # Draw 1px green dot
            draw.point((cx, cy), fill=(0, 255, 0))
    
    vis = np.array(vis_pil)
    
    # Save energy map with grid and centers
    Image.fromarray(vis).save(output_path)
    print(f"Saved energy map: {output_path}")
    print(f"Detected grid lines: {len(x_lines)} × {len(y_lines)}")
    print(f"All grid lines (with interpolation): {len(all_x_lines)} × {len(all_y_lines)}")
    print(f"Grid cell centers: {(len(all_x_lines) - 1) * (len(all_y_lines) - 1)}")
    
    # Generate pixel art if requested
    if args.sample:
        # Determine upscale factor
        if args.upscale > 0:
            upscale_factor = args.upscale
        elif args.native_res:
            upscale_factor = 1
        else:
            # Default: use auto-detected pixel_size or specified pixel-size
            upscale_factor = pixel_size
        
        pixel_art = _sample_pixel_art(
            original_rgb=rgb,
            all_x_lines=all_x_lines,
            all_y_lines=all_y_lines,
            mode=args.sample_mode,
            weight_ratio=float(args.sample_weight_ratio),
            pixel_size=upscale_factor,
            native_res=(upscale_factor == 1)
        )
        
        # Apply color quantization if requested
        if args.quantize:
            pixel_art = _quantize_colors(
                pixel_art,
                mode=args.quantize_mode,
                target_colors=args.colors,
                similarity_threshold=float(args.similarity_threshold)
            )
            if args.quantize_mode == "smart" and args.colors == 0:
                num_pixels = pixel_art.shape[0] * pixel_art.shape[1]
                auto_colors = min(256, max(2, int(np.log2(num_pixels))))
                print(f"Applied smart quantization: {auto_colors} colors (similarity threshold: {args.similarity_threshold})")
            elif args.quantize_mode == "force":
                print(f"Applied force quantization: {args.colors} colors")
        
        # Save pixel art
        pixel_output_path = output_path.parent / f"{output_path.stem}_pixel_art{output_path.suffix}"
        Image.fromarray(pixel_art).save(pixel_output_path)
        print(f"Saved pixel art: {pixel_output_path}")
        
        if upscale_factor == 1:
            print(f"Pixel art size: {pixel_art.shape[1]}x{pixel_art.shape[0]} ({pixel_art.shape[1]}×{pixel_art.shape[0]} pixels) - Native resolution")
        else:
            print(f"Pixel art size: {pixel_art.shape[1]}x{pixel_art.shape[0]} ({pixel_art.shape[1]//upscale_factor}×{pixel_art.shape[0]//upscale_factor} pixels) - {upscale_factor}x upscale")
        
        print(f"Sampling mode: {args.sample_mode}")
        if args.sample_mode == "weighted":
            print(f"Weight ratio: {args.sample_weight_ratio}")
        print(f"Upscale factor: {upscale_factor}x")
        
        if args.quantize:
            if args.quantize_mode == "smart" and args.colors == 0:
                num_pixels = pixel_art.shape[0] * pixel_art.shape[1]
                auto_colors = min(256, max(2, int(np.log2(num_pixels))))
                print(f"Final colors: {auto_colors}")
            elif args.quantize_mode == "force":
                print(f"Final colors: {args.colors}")


if __name__ == "__main__":
    main()